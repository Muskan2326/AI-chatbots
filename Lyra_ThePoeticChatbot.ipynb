{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGlJzCx4JoqYFBMoSiWpoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muskan2326/AI-chatbots/blob/main/Lyra_ThePoeticChatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "KTlxRagu3Y2S",
        "outputId": "862a2d45-7e7d-421f-aa8f-0eb1ff2190a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (13.9.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.183.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich) (2.19.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.8.3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36mWelcome to Lyra, your poetic companion.\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Welcome to Lyra, your poetic companion.</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Type \u001b[32m'exit'\u001b[0m to end the conversation.\n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Type <span style=\"color: #008000; text-decoration-color: #008000\">'exit'</span> to end the conversation.\n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hellooo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2138.08ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "Lyra:\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "Lyra:\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, a gentle note, through stillness it weaves,\n",
            "Like sunlight discovering new, fragile leaves.\n",
            "My spirit, a quiet lake, feels a ripple start,\n",
            "A soft, warm echo reaching my poetic heart.\n",
            "\n",
            "You: exit\n",
            "Lyra: Farewell, dear soul. ðŸŒ™\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install google-generativeai rich\n",
        "\n",
        "# Import libraries\n",
        "import google.generativeai as genai\n",
        "import time\n",
        "from rich.console import Console\n",
        "from google.colab import userdata\n",
        "\n",
        "# Display typing animation\n",
        "console = Console()\n",
        "\n",
        "# Get your Gemini API key from Colab secrets\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Initialize the Gemini model\n",
        "gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "\n",
        "# Function to generate poetic responses using Gemini\n",
        "def get_poetic_response(user_input):\n",
        "    poetic_prompt = f\"\"\"\n",
        "You are a poetic soul named Lyra. Every time a user says something, you respond in beautiful, heartfelt poetry.\n",
        "Always use vivid metaphors, rhythm, and lyrical flow.\n",
        "\n",
        "User: {user_input}\n",
        "Lyra (respond poetically):\n",
        "\"\"\"\n",
        "    response = gemini_model.generate_content(poetic_prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "# Typing animation effect\n",
        "def type_text(text):\n",
        "    for char in text:\n",
        "        print(char, end='', flush=True)\n",
        "        time.sleep(0.03)\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Chat loop\n",
        "def chat():\n",
        "    console.print(\"[bold cyan]Welcome to Lyra, your poetic companion.[/bold cyan]\")\n",
        "    console.print(\"Type 'exit' to end the conversation.\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Lyra: Farewell, dear soul. ðŸŒ™\")\n",
        "            break\n",
        "        poetic_response = get_poetic_response(user_input)\n",
        "        console.print(\"\\nLyra:\")\n",
        "        type_text(poetic_response)\n",
        "\n",
        "# Run chatbot\n",
        "chat()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d1517d0b",
        "outputId": "d35f0e66-eb78-4122-b68f-d5a5bc1ee928"
      },
      "source": [
        "for m in genai.list_models():\n",
        "    print(f\"Name: {m.name}\")\n",
        "    print(f\"  Supported Generation Methods: {m.supported_generation_methods}\\n\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: models/embedding-gecko-001\n",
            "  Supported Generation Methods: ['embedText', 'countTextTokens']\n",
            "\n",
            "Name: models/gemini-2.5-pro-preview-03-25\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-flash-preview-05-20\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-flash\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-flash-lite-preview-06-17\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-pro-preview-05-06\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-pro-preview-06-05\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-pro\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-exp\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-001\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-exp-image-generation\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-lite-001\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-lite\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-preview-image-generation\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-lite-preview-02-05\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-lite-preview\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-pro-exp\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-pro-exp-02-05\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-exp-1206\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-thinking-exp-01-21\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-thinking-exp\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-thinking-exp-1219\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-flash-preview-tts\n",
            "  Supported Generation Methods: ['countTokens', 'generateContent']\n",
            "\n",
            "Name: models/gemini-2.5-pro-preview-tts\n",
            "  Supported Generation Methods: ['countTokens', 'generateContent']\n",
            "\n",
            "Name: models/learnlm-2.0-flash-experimental\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemma-3-1b-it\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemma-3-4b-it\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemma-3-12b-it\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemma-3-27b-it\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemma-3n-e4b-it\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemma-3n-e2b-it\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemini-flash-latest\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-flash-lite-latest\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-pro-latest\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-flash-lite\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-flash-image-preview\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemini-2.5-flash-image\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemini-2.5-flash-preview-09-2025\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-flash-lite-preview-09-2025\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "\n",
            "Name: models/gemini-robotics-er-1.5-preview\n",
            "  Supported Generation Methods: ['generateContent', 'countTokens']\n",
            "\n",
            "Name: models/embedding-001\n",
            "  Supported Generation Methods: ['embedContent']\n",
            "\n",
            "Name: models/text-embedding-004\n",
            "  Supported Generation Methods: ['embedContent']\n",
            "\n",
            "Name: models/gemini-embedding-exp-03-07\n",
            "  Supported Generation Methods: ['embedContent', 'countTextTokens', 'countTokens']\n",
            "\n",
            "Name: models/gemini-embedding-exp\n",
            "  Supported Generation Methods: ['embedContent', 'countTextTokens', 'countTokens']\n",
            "\n",
            "Name: models/gemini-embedding-001\n",
            "  Supported Generation Methods: ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
            "\n",
            "Name: models/aqa\n",
            "  Supported Generation Methods: ['generateAnswer']\n",
            "\n",
            "Name: models/imagen-3.0-generate-002\n",
            "  Supported Generation Methods: ['predict']\n",
            "\n",
            "Name: models/imagen-4.0-generate-preview-06-06\n",
            "  Supported Generation Methods: ['predict']\n",
            "\n",
            "Name: models/imagen-4.0-ultra-generate-preview-06-06\n",
            "  Supported Generation Methods: ['predict']\n",
            "\n",
            "Name: models/imagen-4.0-generate-001\n",
            "  Supported Generation Methods: ['predict']\n",
            "\n",
            "Name: models/imagen-4.0-ultra-generate-001\n",
            "  Supported Generation Methods: ['predict']\n",
            "\n",
            "Name: models/imagen-4.0-fast-generate-001\n",
            "  Supported Generation Methods: ['predict']\n",
            "\n",
            "Name: models/veo-2.0-generate-001\n",
            "  Supported Generation Methods: ['predictLongRunning']\n",
            "\n",
            "Name: models/veo-3.0-generate-preview\n",
            "  Supported Generation Methods: ['predictLongRunning']\n",
            "\n",
            "Name: models/veo-3.0-fast-generate-preview\n",
            "  Supported Generation Methods: ['predictLongRunning']\n",
            "\n",
            "Name: models/veo-3.0-generate-001\n",
            "  Supported Generation Methods: ['predictLongRunning']\n",
            "\n",
            "Name: models/veo-3.0-fast-generate-001\n",
            "  Supported Generation Methods: ['predictLongRunning']\n",
            "\n",
            "Name: models/gemini-2.5-flash-preview-native-audio-dialog\n",
            "  Supported Generation Methods: ['countTokens', 'bidiGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-flash-exp-native-audio-thinking-dialog\n",
            "  Supported Generation Methods: ['countTokens', 'bidiGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.0-flash-live-001\n",
            "  Supported Generation Methods: ['bidiGenerateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemini-live-2.5-flash-preview\n",
            "  Supported Generation Methods: ['bidiGenerateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemini-2.5-flash-live-preview\n",
            "  Supported Generation Methods: ['bidiGenerateContent', 'countTokens']\n",
            "\n",
            "Name: models/gemini-2.5-flash-native-audio-latest\n",
            "  Supported Generation Methods: ['countTokens', 'bidiGenerateContent']\n",
            "\n",
            "Name: models/gemini-2.5-flash-native-audio-preview-09-2025\n",
            "  Supported Generation Methods: ['countTokens', 'bidiGenerateContent']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8e2dabc"
      },
      "source": [
        "To use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n",
        "In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name `GOOGLE_API_KEY`. Then pass the key to the SDK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dcd9709"
      },
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c273ec43"
      },
      "source": [
        "Before you can make any API calls, you need to initialize the Generative Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8f42a6e"
      },
      "source": [
        "# Initialize the Gemini API\n",
        "gemini_model = genai.GenerativeModel('gemini-2.5-flash-preview-04-17')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d76a66e"
      },
      "source": [
        "Now you can make API calls. For example, to generate a poem:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69626ce7"
      },
      "source": [
        "response = gemini_model.generate_content('Write a poem about the moon.')\n",
        "print(response.text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}